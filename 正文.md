# Summary

# Introduction
## Background
- 网购平台日益崛起，由于订单不受时间、地点的限制和送货上门等优势，许多用户选择在网上购物。但是在网购平台上，用户看不到实物，只能通过商品图片和简介来了解商品，这催生了**评论机制**，即已购买者可以通过星级来表达他们对产品的满意度，还可以通过文本来表达对产品的更多意见和信息。其他客户可以通过阅读这些评论，来协助他们的购买决策。公司也会根据这些评论数据来改进产品设计的优缺点。但我们发现，这些评论中存在用户（可能是竞争对手）恶意的评论和公司通过收买评论者而得到的好评。而这些评价可能对用户的购买决策和接下来的评论内容造成重大影响，我们需要通过分析星级、评论内容和评论时间等数据来得到更为具体的结果。
In recent years, quantities of customers prefer to shopping online for its less spacetime limitation and the convenient home delivery service. However, compared to the traditional physical stores, customers can only evaluate products by the provided profile and pictures instead of seeing or testing the real ones. The information gap here is one of the leading causes of dissatisfied purchases. To help customers know the product better, many online marketplace platforms, such as Amazon, launch a "review system". Customers can express their level of satisfaction and further opinions or information about purchases through rating and reviewing. That additional information can help not only other customers make purchasing decisions, but companies improve the pros and cons of product design.
However, we found that not all reviews are equally relevant. Some reviews are too general; some people's ratings do not match their reviews; there are even deliberately misleading reviews, such as malicious defamation from competitors or the raise by the bribed reviewers. Therefore, when using data to assist business decisions, we need to analyze data carefully and comprehensively to obtain more accurate results. More factors should be considered, such as the ratings, review contents and review time, rather than straightly calculate the average rating level.
> 已翻译

<details>
<summary>mzq爬</summary>
~~With the rise of the online marketplace, quantities of people are used to shopping online for its convenient and active service.  However, in the online marketplace, customers can only gain product information through the picture and profile for they can't touch, see, and test the product personally. Fortunately, the online marketplace provides customers with an opportunity to rate and review purchases, which gives them a stage to represent their satisfaction with a product. Purchasers can give star ratings and submit messages that express further information and opinions about the product. These reviews help not only browsers make purchasing decisions, but companies improve the pros and cons of product design. However, we found that there are malicious comments from customers(possibly competitors) and groups of positive reviews which may come from a click farm. These comments may have a significant impact on the customers' purchasing decisions and purchasers' future ratings and reviews. We need to analyze the data of star rating, review content and review time to identify key patterns or measures on product desirability or reputation.~~
</details>

## Problem analysis
- 通过分析三个产品数据集，描述有助于评估产品的星级、评论和帮助等级的定量和/或定性模式、关系、度量和参数，并用数据证明他们确实有用。
- 通过建模解决以下问题
	- 根据ratings和reviews确定一个最informative的度量，这个度量可以跟踪三种产品上市后的产品评级。
	- 分别在三个数据集里，分析产品评级和时间的关系。
	- 寻找能影响产品评级拐点的关键因素。
	- 分析一段时间内是否会有较为集中的好评或差评，客户star rating是否会被最近评论影响。
	- 评级star rating和评论内容review的关键字是否匹配。
- Analyze the three product data sets to describe quantitative and/or qualitative patterns, relationships that help evaluate a product's star ratings, reviews and helpfulness ratings. Use data to demonstrate that they are valuable.
- Solve the following issues through modelling:
	- Determine the most informative metric based on ratings and reviews. This metric can track the product ratings of three products when they are on the market.
	- Analyze the relationship between product ratings and time in three data sets.
	- Look for critical factors that can affect the inflexion point of product ratings through time.
	- Analyze whether there will be more a series of positive or negative reviews over a while and whether customer star ratings will be affected by recent reviews.
	- Whether star rating and the keyword of review content match.
> 已翻译

## DataSource
- Our model is informed by the customer-supplied ratings and reviews for microwave ovens, baby pacifiers, and hair dryers sold in the Amazon marketplace over more than ten years.
> 已翻译

## Data Pre-processing
- 删除冗余
	- 地区marketplace
	- 商品种类product_category;
	- 没有使用：评论标识review_id; 产品标识product_id
- 删除错误数据
	- `verify_purchase == N`的评论全部删除
- We did the following to sanitize the data set:
	- Remove factors that were not measured at all, such as marketplace and product category, for they can not present any information.
	- Remove the redundant factors, such as review_id and product_id, for they can be completely replaced by customer_id and product_parent.
	- Remove factors that could mislead the model, such as verify_purchase == N.
	- Remove some garbled character
> 已翻译

# Assumption
- 商家的目的：通过优质评论和近期评论引导用户购买产品
	- 根据题目要求理解得到
- 评论内容和星级评定应保持基本一致，不一致时人们更相信评论
	- 基于大众心理，真实的语言更令人信服
- 特邀测评员的评论更可信 `vine == Y`，不包含因免费获得产品而打高分的主观性因素
	- 由网购平台选出的特邀测评员是有大数据支持的，他们的评价更为客观、有效。
- 实际购买人的评论更可信 `verify_purchase == Y`
	- 已经体验过产品的人更了解产品的真实性能
- 实际未购买人的评论完全不可信 `verify_purchase == N`
	- 列出未购买人与购买人与全体之间1-5星的分布，可以看出未购买人中1星较其他两项多很多，考虑是竞争对手恶意评论或已购买人不满意产品或服务从而邀请亲友（未购买）为其打低分来报复商家。
		- fig1
		- fig2
- 不考虑同一购买者对评论的影响，即购买者的每次评价行为都是独立的，和上次自己的评价无关。
- Merchant's purpose: Guide users to buy products with quality reviews and recent reviews

- The content of the review and the star rating should be the same. People believe in reviews when review content is inconsistent with star ratings.
	- Based on popular psychology, real language is convincing 
- Amazon Vine members' reviews are credible `vine == Y`, excluding subjective factors that give high ratings for free products
	- Big data select Amazon Vine members. Their evaluations are more objective and practical.
- Actual purchasers' reviews are credible. `verify_purchase == Y`
	- People who have already experienced the product know more about the actual performance of the product.
- Comments from actual non-purchasers are untrustworthy.`verify_purchase == N`
	- We listed the distribution of 1-5 stars between the non-purchasers and the purchasers. It shows that the non-purchasers give more 1 star than purchasers, which may mislead the reviews.
	- fig 1: Compare the non-purchasers with the purchasers on star_rating
		- fig 1.1: hair dryer
		- fig 1.2: microwave
		- fig 1.3: pacifier
	- fig 2: Purchaser to non-purchaser ratio
		- fig 2.1: hair dryer
		- fig 2.2: microwave
		- fig 2.3: pacifier
- The impact of the same purchaser on reviews is not taken into consideration; that is, each evaluation behaviour of the purchaser is independent and not related to the previous reviews.
> 已翻译，但未插入图片

# Nomenclature
## Symbol
- star$_{i}$: star rating of a review i
  
- ER$_{i}$: emtional rating of a review i
  
- d$_{i}$: the variance between star rating and emtional rating of a review i

- L$_{i}$: length of a review i

- Vm$_{i}$: whether a review i is from an Amazon vine member
  
- Vr$_{i}$: votes rating of a review i
  
- M$_{i}$: rating of a review i

- Q$_{i}$: quality of a review i
      
- R$_{i}$: synthesize evaluation of a review i
 
- R: average review synthesize evaluation
  
- t: time


- 我不太会起符号，现在是以英文缩写为基本，已知量为小写，待定（或者说是需要计算得到的）量为大写 ——mzq
## Definition
- star rating of a review i
- emtional rating of a review i
- measures the variance between star rating and emtional rating of a review i
- length of a review i
	- real length divided by a critical value, range from 0 to 1
- whether a review i is from an Amazon vine member
	- yes, Vm_i=1; no, Vm_i=0;
- votes rating of a review i
	- helpful votes divided by total votes, range from 0 to 1

- rating of a review i
- quality of a review i
- synthesize evaluation of a review i
- average review evaluation
- time
> 已翻译
> table 1: Variables and functions

# Model Design

## Review Content: M_i
When a user evaluates a product, he will simultaneously commit a rating and a review. These two indicators together describe his satisfaction with the product. Therefore, we can consider that the positive degree of ratings and reviews posted together are highly positively correlated in general. However, for various reasons, exceptions may occur. For example, someone may give a rating that is inconsistent with his review because of an operation error; or someone may give a higher star rating because of habit or because of a bribe from the merchant, although they are not very satisfied with the product. Therefore, when analyzing the user's evaluation of the product, we think that we should consider the influence of the rating and the review comprehensively, rather than simply counting the rating.

Because reviews are in the form of text, we need to process them first, to get a quantitative measure of user satisfaction with the product toward the review context. Reviews are generally too short for analysis using the LDA model, but we found that most of the reviews have apparent keywords. Therefore, we use the statistical method instead of NLP.
In each data set, we performed the following steps
- Perform word frequency statistics on each rating level, respectively.
- Calculate the probability of each word appearing in different rating
- Filter out words that have practical meaning and have noticeable frequency differences in different ratings
- weighted them with the probability get a "rating" corresponding to a word
In this way, we have a word-rating dictionary. Then in each review, we mark the above keywords and find the average rating of all keyword. Finally, according to the above algorithm, we got a review's "emotional rating" ER_i.

Taking the hair-dryer as an example: the following charts show some of the data in the process.

Next, we need to get a measure M_i of a review that considers star_i and ER_i comprehensively.
According to our initial assumptions, if the difference between the rating and the review score is too large, it indicates that there may be some problem with this review, which can be of low reference value and should be ignored in statistics. However, from the existing data, there is not a very appropriate indicator for the measurement of the difference. Ideally, the "useful vote" of other users for reviews should be the best standard for measuring the quality and authenticity of reviews; a joint analysis can be used to find out the threshold of ignoring unreliable reviews. However, there is too little voting data for reviews in the provided data for effective analysis. 【此处插入一个统计或者图标，说明多数没投票，或者只有个位数的票】
So we decided to take another strategy. On the one hand, when posting a comment, it only takes one click to give a star rating, but a paragraph of text is required to give a review. Obviously, the former has a higher probability of misoperation. On the other hand, reviews are more informative and detailed than review stars. From life experience, in the face of a mismatch between a star rating and a review, users are more willing to believe the latter. So after a series of attempts, we finally decided to use the formula
$ M_i = 0.7 \ times ER_i + 0.3 \ times star_i $
As a measure of the content of the review.

## Review quality: Q_i
Using M_i, we can get a user's evaluation of the product. However, from the perspective of all reviews, each review has different reliability. In the data given, we believe that the following factors can reflect the credibility and accuracy of a review to some extent.

### Comment votes rate: Vr_i
Although the amount of helpful vote data is not enough to be a criterion for the quality of comments, we can still consider that reviews with a higher voting rate are more helpful than those with a lower one. We quantify the votes rate as follows:
$$
Vr_i = 
\begin{cases}  
	\frac{helpful\_votes}{total\_votes}, &\text{if total_votes > 0} \\
	0, &\text{if total_votes = 0}
\end{cases}
$$

### Length of review: L_i
According to a study by Huang and Chen (reference link"A study of factors that contribute to online review helpfulness"), the helpfulness of online review and its length has a significant positive correlation when the reviews are short enough (less than 144 words). As reviews get long, the correlation decreases. Meanwhile, the strengthening effect of review length on its helpfulness gradually decreases. Therefore, we choose to use a logarithmic function to characterize the impact of the reviews' length on its quality. Furthermore, when the length reaches a certain threshold, the review quality no longer increases. We quantify the length factor as follows:
$$
L_i =
\begin{cases}  
	 lg (length of review), &\text{if lenth of review < 100 words} \\
	2, &\text{else}
\end{cases}
$$

### Vine Voice: vm_i
Amazon Vine Voices are trusted users in the Amazon community for writing accurate and insightful reviews. So we can consider reviews made by them to be more accurate and reliable. The discrete variable vm_i is used to characterize whether the customer who did this review is a Vine Voice:

$$
Vm = 
\begin{cases}  
	1, &\text{if vine = Y} \\
	0, &\text{if vine = N}
\end{cases}
$$

### Difference between ER_i and star_i: d_i
As we discussed earlier, there may be various reasons why the text of the review does not match the star rating given. We consider these reviews to be relatively unreliable, and the degree of bias is negatively related to the credibility of the reviews. We use the following formula to quantify the impact of review mismatch with star ratings on review quality:
$d_i  = -|ER - star|$

# Sensitivity Analysis

# Strengths and Weaknesses

## Strengths
- 
## Weaknesses and Improvement
- 不管是使用词频分析或是LDA情感分析，都存在数据较少而导致模型存在误差
- 使用LDA模型分析短评论会和星级评分出现较大的误差
- 不同人对评价可能存在不同标准，这时需要研究每个人的评价习惯，根据不同习惯赋予不同权值
- 删除未购买者的评论对问题分析是有用的，但是这些评论仍能被浏览者看到，并且影响他们的购物决策。我们这方面欠缺考虑。
- The small dataset causes deviation of the model which build by either word frequency analysis or LDA.
- The LDA model has an excellent performance with document collection, while the majority of reviews are short in words. 
- While major reviewers are not Amazon Vine Member, different people may have different criteria for evaluation, which may produce an objective assessment. We need to study every reviewers' rating habit to get a weight for every reviewer.
- Removing the non-purchasers' reviews helps analysis the problem; however, these 
> 已翻译

# Letter
- subject: Data Analysis Results
- content
Dear Marketing Director,
感谢您对我们的团队的信任，我们已经了解到您希望从评分和评论入手，得到一些相关参数或度量来量化产品声誉，从而提高产品吸引力和销量。经过慎重考虑后，我们建立了一个可以分析产品综合评分的模型，来帮助您识别产品的声誉和它们在在线市场中是否成功。
我们分析数据发现，不能单从星级来评估产品的好坏和声誉。因为不仅存在星级和评论内容不符的情况，还有一些未购买者对产品做不合理评价的情况。这些有问题的星级和评论会误导顾客，影响他们的购物决策，损坏产品声誉，甚至影响将来的评论走势。

我们首先将未购买者的评论从数据中剔除，这能尽可能地减少恶意评论者损坏产品的声誉。我们也希望您能向亚马逊提出设置未购买者不可评论在线商品的建议，这一做法可以有效提高您的产品声誉进而影响销量。
我们再通过TD-IDF信息检索和数据挖掘技术学习了每条评论，通过分析不同词汇出现不同星级的频率，给出每条评论的情感得分，这个分数表明了每条评论的实际语义。通过评论情感分数可以计算每个评论的星级和评论内容的符合程度。我们发现大部分星级和评论是相关的，但也存在一些不太相符的数据。这说明大部分星级数据都可以用来代表产品的好坏，而部分的评论也应加权值纳入考虑。

我们认为产品声誉和产品好坏是有区别的，因为不同质量的评论会对产品的声誉造成不同的影响。一个‘Perfect’只能带给顾客微小的信息量，而一个描述详细的好评会带给顾客更多的信息。人们会更加相信vine member的评论和有用率（votes rating）高的评论。
我们建立了评论质量得分模型，当星级和评论感情得分相近时，质量更高；当星级和评论感情得分不符时，质量更低。
我们用评论字长、有用率、是否为优秀评价者和评论质量得分这四个factor来描述评论综合评级。综合评级可以代表产品的声誉。





